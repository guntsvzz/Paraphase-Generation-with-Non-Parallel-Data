{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "qq = pd.read_csv('./Datasets/quora_question.csv')\n",
    "qq.drop(columns=['test_id','question2'], inplace=True)\n",
    "qq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample = qq.sample(n=1000,random_state=6969) #try only 1000 samples\n",
    "random_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614123</th>\n",
       "      <td>Why won't China let Pope Francis visit?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795359</th>\n",
       "      <td>Is it common to say \"you are welcome\" in when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209942</th>\n",
       "      <td>Do G+ \"plus ones\" on posts actually do anythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383030</th>\n",
       "      <td>Can llp give loan to its partners?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529755</th>\n",
       "      <td>How many medals become won in Olympics ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question1\n",
       "614123             Why won't China let Pope Francis visit?\n",
       "795359   Is it common to say \"you are welcome\" in when ...\n",
       "2209942  Do G+ \"plus ones\" on posts actually do anythin...\n",
       "1383030                 Can llp give loan to its partners?\n",
       "529755            How many medals become won in Olympics ?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq1000 = random_sample['question1'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# benepar.download('benepar_en3')\n",
    "import benepar, spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe('benepar', config={'model': 'benepar_en3'})\n",
    "\n",
    "def constituency_parser(text):\n",
    "    doc = nlp(text)\n",
    "    sent = list(doc.sents)[0]\n",
    "    return  \"(ROOT \"+sent._.parse_string+\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guntsv\\AppData\\Local\\Temp\\ipykernel_9848\\3282338791.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx in tqdm_notebook(range(len(qq1000))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c5a75392124ea9a8189bfa95f4e820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Python3.10.4\\lib\\site-packages\\torch\\distributions\\distribution.py:45: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "train_data = list()\n",
    "for idx in tqdm_notebook(range(len(qq1000))):\n",
    "    train_data.append([qq1000[idx],constituency_parser(qq1000[idx])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>parser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why won't China let Pope Francis visit?</td>\n",
       "      <td>(ROOT (SBARQ (WHADVP (WRB Why)) (SQ (MD wo) (R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it common to say \"you are welcome\" in when ...</td>\n",
       "      <td>(ROOT (SQ (VBZ Is) (NP (NP (PRP it))) (ADJP (J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do G+ \"plus ones\" on posts actually do anythin...</td>\n",
       "      <td>(ROOT (SQ (VBP Do) (NP (NP (`` G+) (`` \") (CC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can llp give loan to its partners?</td>\n",
       "      <td>(ROOT (SQ (MD Can) (NP (NN llp)) (VP (VB give)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many medals become won in Olympics ?</td>\n",
       "      <td>(ROOT (SBARQ (WHNP (WHADJP (WRB How) (JJ many)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0            Why won't China let Pope Francis visit?   \n",
       "1  Is it common to say \"you are welcome\" in when ...   \n",
       "2  Do G+ \"plus ones\" on posts actually do anythin...   \n",
       "3                 Can llp give loan to its partners?   \n",
       "4           How many medals become won in Olympics ?   \n",
       "\n",
       "                                              parser  \n",
       "0  (ROOT (SBARQ (WHADVP (WRB Why)) (SQ (MD wo) (R...  \n",
       "1  (ROOT (SQ (VBZ Is) (NP (NP (PRP it))) (ADJP (J...  \n",
       "2  (ROOT (SQ (VBP Do) (NP (NP (`` G+) (`` \") (CC ...  \n",
       "3  (ROOT (SQ (MD Can) (NP (NN llp)) (VP (VB give)...  \n",
       "4  (ROOT (SBARQ (WHNP (WHADJP (WRB How) (JJ many)...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame(train_data)\n",
    "train_data.rename(columns={0:'sentence',1:'parser'},inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(text):\n",
    "    return  \"<SOS> \"+ text + \" <EOS>\"\n",
    "\n",
    "train_data['target'] = train_data['sentence'].apply(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>parser</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why won't China let Pope Francis visit?</td>\n",
       "      <td>(ROOT (SBARQ (WHADVP (WRB Why)) (SQ (MD wo) (R...</td>\n",
       "      <td>&lt;SOS&gt; Why won't China let Pope Francis visit? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it common to say \"you are welcome\" in when ...</td>\n",
       "      <td>(ROOT (SQ (VBZ Is) (NP (NP (PRP it))) (ADJP (J...</td>\n",
       "      <td>&lt;SOS&gt; Is it common to say \"you are welcome\" in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do G+ \"plus ones\" on posts actually do anythin...</td>\n",
       "      <td>(ROOT (SQ (VBP Do) (NP (NP (`` G+) (`` \") (CC ...</td>\n",
       "      <td>&lt;SOS&gt; Do G+ \"plus ones\" on posts actually do a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can llp give loan to its partners?</td>\n",
       "      <td>(ROOT (SQ (MD Can) (NP (NN llp)) (VP (VB give)...</td>\n",
       "      <td>&lt;SOS&gt; Can llp give loan to its partners? &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many medals become won in Olympics ?</td>\n",
       "      <td>(ROOT (SBARQ (WHNP (WHADJP (WRB How) (JJ many)...</td>\n",
       "      <td>&lt;SOS&gt; How many medals become won in Olympics ?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0            Why won't China let Pope Francis visit?   \n",
       "1  Is it common to say \"you are welcome\" in when ...   \n",
       "2  Do G+ \"plus ones\" on posts actually do anythin...   \n",
       "3                 Can llp give loan to its partners?   \n",
       "4           How many medals become won in Olympics ?   \n",
       "\n",
       "                                              parser  \\\n",
       "0  (ROOT (SBARQ (WHADVP (WRB Why)) (SQ (MD wo) (R...   \n",
       "1  (ROOT (SQ (VBZ Is) (NP (NP (PRP it))) (ADJP (J...   \n",
       "2  (ROOT (SQ (VBP Do) (NP (NP (`` G+) (`` \") (CC ...   \n",
       "3  (ROOT (SQ (MD Can) (NP (NN llp)) (VP (VB give)...   \n",
       "4  (ROOT (SBARQ (WHNP (WHADJP (WRB How) (JJ many)...   \n",
       "\n",
       "                                              target  \n",
       "0  <SOS> Why won't China let Pope Francis visit? ...  \n",
       "1  <SOS> Is it common to say \"you are welcome\" in...  \n",
       "2  <SOS> Do G+ \"plus ones\" on posts actually do a...  \n",
       "3     <SOS> Can llp give loan to its partners? <EOS>  \n",
       "4  <SOS> How many medals become won in Olympics ?...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer('spacy',language='en_core_web_sm')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter.itertuples(index=False):\n",
    "        yield tokenizer(text)\n",
    "    #loop through the data_iter, \n",
    "    # Mind that the data_iter in this case is pandas Dataframe\n",
    "    # pass #remove this line and code here\n",
    "\n",
    "specials = ['<unk>','<pad>','<bos>','<eos>'] #create array of special tags for the vocab\n",
    "vocab_transform  = build_vocab_from_iterator(yield_tokens(train_data), specials = specials, special_first=True)\n",
    "\n",
    "#set_default_index of the vocab to unknown tag\n",
    "vocab_transform.set_default_index(vocab_transform[\"<unk>\"]) #if you don't the id of this word, set it unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3407"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(vocab_transform) == 3407 #only for 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<bos>', '<eos>', '?', 'the', 'What', 'a', 'is', 'I']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transform.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('vocab_transform_cnn.pickle', 'wb') as f:\n",
    "#     pickle.dump(vocab_transform, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('vocab_transform_cnn.pickle', 'rb') as f:\n",
    "    vocab_transform = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\wiki.simple.vec: 293MB [00:25, 11.4MB/s]                               \n",
      "  0%|          | 0/111051 [00:00<?, ?it/s]Skipping token b'111051' with 1-dimensional vector [b'300']; likely a header\n",
      "100%|██████████| 111051/111051 [00:11<00:00, 9527.14it/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "from torchtext.vocab import FastText\n",
    "fast_vectors = FastText(language='simple') ##Load fasttext with language = simple\n",
    "fast_embedding = fast_vectors.get_vecs_by_tokens(vocab_transform.get_itos()).to(device)\n",
    "\n",
    "#since the fasttext  has 300 embedding\n",
    "assert fast_embedding.shape == (len(vocab_transform), 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "pad_idx = vocab_transform['<pad>'] ##get the pad index from the vocab\n",
    "\n",
    "def collate_batch(batch):\n",
    "    ## copy the collate_batch function from Professor's code. But it will not work right away\n",
    "    #mind how the dataset that we use is structured (hint: columns)\n",
    "    label_list, text_list = [], []\n",
    "    for (_text, _label) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "    #criterion expects float labels\n",
    "    return torch.tensor(label_list, dtype=torch.int64), pad_sequence(text_list, padding_value=pad_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "torch.manual_seed(6969)\n",
    "\n",
    "train = train_data[:800]\n",
    "val   = train_data[800:900] \n",
    "test  = train_data[900:]\n",
    "train_dataloader = DataLoader(train,batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(val,  batch_size=16)\n",
    "test_dataloader = DataLoader(test,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Finance: Which is be an Auroville resident for a long time?', 'How do pool leave my country?', 'What is food?', 'What does \"in line boys mean of the phrase this?', 'For atheists, are morals to subjective?', 'Which programming language was used to Facebook?', 'Despite being relatively poor at programming, I want to work harder, and one day reach the International Finals of ACM ICPC. How do I go about it?', 'How can I reduce my belly fat in 2 months?', 'What does Stanley leather master mean?', 'How do I earn money in my free energy?', 'Which operating system is safer: Windows, OS X, or Linux? Why?', 'What does \";-;\" exam after 10th?', 'How can I study communication?', 'How do you clean general a coffee maker?', 'Why do assassin?', 'How was your experience palace in a relationship?')\n",
      "('(ROOT (NP (NP (NN Finance)) (: :) (WHNP (WDT Which)) (SQ (VBZ is) (VP (VB be) (NP (DT an) (NNP Auroville) (NN resident)) (PP (IN for) (NP (DT a) (JJ long) (NN time))))) (. ?)))', '(ROOT (SBARQ (WHADVP (WRB How)) (SQ (VBP do) (NP (NN pool)) (VP (VB leave) (NP (PRP$ my) (NN country)))) (. ?)))', '(ROOT (SBARQ (WHNP (WP What)) (SQ (VBZ is) (NP (NN food))) (. ?)))', '(ROOT (SBARQ (WHNP (WP What)) (SQ (VBZ does) (`` \") (NP (PP (IN in) (NP (NN line))) (NP (NNS boys))) (VP (VB mean) (PP (IN of) (NP (NP (DT the) (NN phrase)) (NP (DT this)))))) (. ?)))', '(ROOT (SQ (PP (IN For) (NP (NNS atheists))) (, ,) (VBP are) (NP (NNS morals)) (ADJP (TO to) (ADJP (JJ subjective))) (. ?)))', '(ROOT (SBARQ (WHNP (WDT Which) (NN programming) (NN language)) (SQ (VBD was) (VP (VBN used) (PP (IN to) (NP (NNP Facebook))))) (. ?)))', '(ROOT (S (PP (IN Despite) (S (VP (VBG being) (ADJP (RB relatively) (JJ poor) (PP (IN at) (NP (NN programming))))))) (, ,) (NP (PRP I)) (VP (VBP want) (S (VP (TO to) (VP (VP (VB work) (ADVP (RBR harder))) (, ,) (CC and) (VP (NP (CD one) (NN day)) (VP (VB reach) (NP (NP (DT the) (NNP International) (NNPS Finals)) (PP (IN of) (NP (NNP ACM) (NNP ICPC)))))))))) (. .)))', '(ROOT (SBARQ (WHADVP (WRB How)) (SQ (MD can) (NP (PRP I)) (VP (VB reduce) (NP (PRP$ my) (NN belly) (NN fat)) (PP (IN in) (NP (CD 2) (NNS months))))) (. ?)))', '(ROOT (SBARQ (WHNP (WP What)) (SQ (VBZ does) (NP (NNP Stanley) (NN leather) (NN master)) (VP (VB mean))) (. ?)))', '(ROOT (SBARQ (WHADVP (WRB How)) (SQ (VBP do) (NP (PRP I)) (VP (VB earn) (NP (NN money)) (PP (IN in) (NP (PRP$ my) (JJ free) (NN energy))))) (. ?)))', '(ROOT (SBARQ (SBAR (WHNP (WDT Which) (VBG operating) (NN system)) (S (VP (VBZ is) (ADJP (JJR safer))))) (: :) (NP (NP (NNP Windows)) (, ,) (NP (NNP OS) (NNP X)) (, ,) (CC or) (NP (NNP Linux))) (. ?)))', '(ROOT (SBARQ (WHNP (WP What)) (SQ (VBZ does) (`` \") (: ;) (: -) (: ;) (\\'\\' \") (VP (VB exam) (PP (IN after) (NP (JJ 10th))))) (. ?)))', '(ROOT (SBARQ (WHADVP (WRB How)) (SQ (MD can) (NP (PRP I)) (VP (VB study) (NP (NN communication)))) (. ?)))', '(ROOT (SBARQ (WHADVP (WRB How)) (SQ (VBP do) (NP (PRP you)) (VP (VB clean) (ADJP (JJ general)) (NP (DT a) (NN coffee) (NN maker)))) (. ?)))', '(ROOT (SBARQ (WHADVP (WRB Why)) (SQ (VBP do) (NP (NN assassin))) (. ?)))', '(ROOT (SBARQ (WHADVP (WRB How)) (SQ (VBD was) (NP (PRP$ your) (NN experience)) (NP (NP (NN palace)) (PP (IN in) (NP (DT a) (NN relationship))))) (. ?)))')\n"
     ]
    }
   ],
   "source": [
    "for sents, syns, trgs in train_dataloader:\n",
    "    print(sents)\n",
    "    print(syns)\n",
    "    print(trgs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_paren(tok):\n",
    "    return tok == \")\" or tok == \"(\"\n",
    "\n",
    "def deleaf(tree):\n",
    "    nonleaves = ''\n",
    "    for w in str(tree).replace('\\n', '').split():\n",
    "        w = w.replace('(', '( ').replace(')', ' )')\n",
    "        nonleaves += w + ' '\n",
    "\n",
    "    arr = nonleaves.split()\n",
    "    for n, i in enumerate(arr):\n",
    "        if n + 1 < len(arr):\n",
    "            tok1 = arr[n]\n",
    "            tok2 = arr[n + 1]\n",
    "            if not is_paren(tok1) and not is_paren(tok2):\n",
    "                arr[n + 1] = \"\"\n",
    "\n",
    "    nonleaves = \" \".join(arr)\n",
    "    return nonleaves.split()\n",
    "\n",
    "from nltk import ParentedTree\n",
    "\n",
    "def Parsetokenize(synt_):\n",
    "    synt_ = ParentedTree.fromstring(synt_)\n",
    "    synt_ = deleaf(synt_)\n",
    "    return synt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(', 'ROOT', '(', 'NP', '(', 'NP', '(', 'NN', ')', ')']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ParentedTree\n",
    "synt_ = '(ROOT (NP (NP (NN Finance)) (: :) (WHNP (WDT Which)) (SQ (VBZ is) (VP (VB be) (NP (DT an) (NNP Auroville) (NN resident)) (PP (IN for) (NP (DT a) (JJ long) (NN time))))) (. ?)))'\n",
    "synt_ = ParentedTree.fromstring(synt_)\n",
    "synt_ = deleaf(synt_)\n",
    "synt_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
