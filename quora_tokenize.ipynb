{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "qq = pd.read_csv('./Datasets/quora_question.csv')\n",
    "qq.drop(columns=['test_id','question2'], inplace=True)\n",
    "qq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample = qq.sample(n=1000,random_state=6969) #try only 1000 samples\n",
    "random_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614123</th>\n",
       "      <td>Why won't China let Pope Francis visit?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795359</th>\n",
       "      <td>Is it common to say \"you are welcome\" in when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209942</th>\n",
       "      <td>Do G+ \"plus ones\" on posts actually do anythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383030</th>\n",
       "      <td>Can llp give loan to its partners?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529755</th>\n",
       "      <td>How many medals become won in Olympics ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question1\n",
       "614123             Why won't China let Pope Francis visit?\n",
       "795359   Is it common to say \"you are welcome\" in when ...\n",
       "2209942  Do G+ \"plus ones\" on posts actually do anythin...\n",
       "1383030                 Can llp give loan to its partners?\n",
       "529755            How many medals become won in Olympics ?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq1000 = random_sample['question1'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# benepar.download('benepar_en3')\n",
    "import benepar, spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe('benepar', config={'model': 'benepar_en3'})\n",
    "\n",
    "def constituency_parser(text):\n",
    "    doc = nlp(text)\n",
    "    sent = list(doc.sents)[0]\n",
    "    return  \"(ROOT \"+sent._.parse_string+\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guntsv\\AppData\\Local\\Temp\\ipykernel_12076\\3282338791.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx in tqdm_notebook(range(len(qq1000))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6cfc93cdc94508b51dd6419f6f4913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Python3.10.4\\lib\\site-packages\\torch\\distributions\\distribution.py:45: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "train_data = list()\n",
    "for idx in tqdm_notebook(range(len(qq1000))):\n",
    "    train_data.append([qq1000[idx],constituency_parser(qq1000[idx])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>parser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why won't China let Pope Francis visit?</td>\n",
       "      <td>(ROOT (SBARQ (WHADVP (WRB Why)) (SQ (MD wo) (R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it common to say \"you are welcome\" in when ...</td>\n",
       "      <td>(ROOT (SQ (VBZ Is) (NP (NP (PRP it))) (ADJP (J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do G+ \"plus ones\" on posts actually do anythin...</td>\n",
       "      <td>(ROOT (SQ (VBP Do) (NP (NP (`` G+) (`` \") (CC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can llp give loan to its partners?</td>\n",
       "      <td>(ROOT (SQ (MD Can) (NP (NN llp)) (VP (VB give)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many medals become won in Olympics ?</td>\n",
       "      <td>(ROOT (SBARQ (WHNP (WHADJP (WRB How) (JJ many)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0            Why won't China let Pope Francis visit?   \n",
       "1  Is it common to say \"you are welcome\" in when ...   \n",
       "2  Do G+ \"plus ones\" on posts actually do anythin...   \n",
       "3                 Can llp give loan to its partners?   \n",
       "4           How many medals become won in Olympics ?   \n",
       "\n",
       "                                              parser  \n",
       "0  (ROOT (SBARQ (WHADVP (WRB Why)) (SQ (MD wo) (R...  \n",
       "1  (ROOT (SQ (VBZ Is) (NP (NP (PRP it))) (ADJP (J...  \n",
       "2  (ROOT (SQ (VBP Do) (NP (NP (`` G+) (`` \") (CC ...  \n",
       "3  (ROOT (SQ (MD Can) (NP (NN llp)) (VP (VB give)...  \n",
       "4  (ROOT (SBARQ (WHNP (WHADJP (WRB How) (JJ many)...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "train_data = pd.DataFrame(train_data)\n",
    "train_data.rename(columns={0:'sentence',1:'parser'},inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def target(text):\n",
    "#     return  \"<SOS> \"+ text + \" <EOS>\"\n",
    "\n",
    "train_data['target'] = train_data['sentence'] #.apply(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>parser</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why won't China let Pope Francis visit?</td>\n",
       "      <td>(ROOT (SBARQ (WHADVP (WRB Why)) (SQ (MD wo) (R...</td>\n",
       "      <td>Why won't China let Pope Francis visit?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it common to say \"you are welcome\" in when ...</td>\n",
       "      <td>(ROOT (SQ (VBZ Is) (NP (NP (PRP it))) (ADJP (J...</td>\n",
       "      <td>Is it common to say \"you are welcome\" in when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do G+ \"plus ones\" on posts actually do anythin...</td>\n",
       "      <td>(ROOT (SQ (VBP Do) (NP (NP (`` G+) (`` \") (CC ...</td>\n",
       "      <td>Do G+ \"plus ones\" on posts actually do anythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can llp give loan to its partners?</td>\n",
       "      <td>(ROOT (SQ (MD Can) (NP (NN llp)) (VP (VB give)...</td>\n",
       "      <td>Can llp give loan to its partners?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many medals become won in Olympics ?</td>\n",
       "      <td>(ROOT (SBARQ (WHNP (WHADJP (WRB How) (JJ many)...</td>\n",
       "      <td>How many medals become won in Olympics ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0            Why won't China let Pope Francis visit?   \n",
       "1  Is it common to say \"you are welcome\" in when ...   \n",
       "2  Do G+ \"plus ones\" on posts actually do anythin...   \n",
       "3                 Can llp give loan to its partners?   \n",
       "4           How many medals become won in Olympics ?   \n",
       "\n",
       "                                              parser  \\\n",
       "0  (ROOT (SBARQ (WHADVP (WRB Why)) (SQ (MD wo) (R...   \n",
       "1  (ROOT (SQ (VBZ Is) (NP (NP (PRP it))) (ADJP (J...   \n",
       "2  (ROOT (SQ (VBP Do) (NP (NP (`` G+) (`` \") (CC ...   \n",
       "3  (ROOT (SQ (MD Can) (NP (NN llp)) (VP (VB give)...   \n",
       "4  (ROOT (SBARQ (WHNP (WHADJP (WRB How) (JJ many)...   \n",
       "\n",
       "                                              target  \n",
       "0            Why won't China let Pope Francis visit?  \n",
       "1  Is it common to say \"you are welcome\" in when ...  \n",
       "2  Do G+ \"plus ones\" on posts actually do anythin...  \n",
       "3                 Can llp give loan to its partners?  \n",
       "4           How many medals become won in Olympics ?  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Proprocessed Data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_paren(tok):\n",
    "    return tok == \")\" or tok == \"(\"\n",
    "\n",
    "def deleaf(tree):\n",
    "    nonleaves = ''\n",
    "    for w in str(tree).replace('\\n', '').split():\n",
    "        w = w.replace('(', '( ').replace(')', ' )')\n",
    "        nonleaves += w + ' '\n",
    "\n",
    "    arr = nonleaves.split()\n",
    "    for n, i in enumerate(arr):\n",
    "        if n + 1 < len(arr):\n",
    "            tok1 = arr[n]\n",
    "            tok2 = arr[n + 1]\n",
    "            if not is_paren(tok1) and not is_paren(tok2):\n",
    "                arr[n + 1] = \"\"\n",
    "\n",
    "    nonleaves = \" \".join(arr)\n",
    "    return nonleaves.split()\n",
    "\n",
    "from nltk import ParentedTree\n",
    "\n",
    "def Parsertokenize(synt_):\n",
    "    synt_ = ParentedTree.fromstring(synt_)\n",
    "    synt_ = deleaf(synt_)\n",
    "    synt_ = [f'<{w}>' for w in synt_]\n",
    "    return synt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subwordnmt.apply_bpe import BPE, read_vocabulary\n",
    "import codecs\n",
    "\n",
    "# load bpe codes\n",
    "bpe_codes = codecs.open('./data/bpe.codes', encoding='utf-8')\n",
    "bpe_vocab = codecs.open('./data/vocab.txt', encoding='utf-8')\n",
    "bpe_vocab = read_vocabulary(bpe_vocab, 50)\n",
    "bpe = BPE(bpe_codes, '@@', bpe_vocab, None)\n",
    "\n",
    "def bpetokenize(sent_, target = False):\n",
    " # bpe segment and convert to tensor\n",
    "    sent_ = bpe.segment(sent_).split()\n",
    "    if target:\n",
    "        sent_.insert(0, \"<SOS>\")\n",
    "        sent_.insert(-1, \"<EOS>\")\n",
    "    return sent_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = pd.DataFrame()\n",
    "train_load['sentence'] = train_data['sentence'].apply(bpetokenize)\n",
    "train_load['parser'] = train_data['parser'].apply(Parsertokenize)\n",
    "train_load['target'] = train_data['target'].apply(bpetokenize, target = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>parser</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[W@@, hy, won@@, 't, C@@, h@@, ina, let, P@@, ...</td>\n",
       "      <td>[&lt;(&gt;, &lt;ROOT&gt;, &lt;(&gt;, &lt;SBARQ&gt;, &lt;(&gt;, &lt;WHADVP&gt;, &lt;(&gt;...</td>\n",
       "      <td>[&lt;SOS&gt;, W@@, hy, won@@, 't, C@@, h@@, ina, let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[I@@, s, it, common, to, say, \"@@, you, are, w...</td>\n",
       "      <td>[&lt;(&gt;, &lt;ROOT&gt;, &lt;(&gt;, &lt;SQ&gt;, &lt;(&gt;, &lt;VBZ&gt;, &lt;)&gt;, &lt;(&gt;,...</td>\n",
       "      <td>[&lt;SOS&gt;, I@@, s, it, common, to, say, \"@@, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[D@@, o, G@@, +, \"@@, plus, on@@, es@@, \", on,...</td>\n",
       "      <td>[&lt;(&gt;, &lt;ROOT&gt;, &lt;(&gt;, &lt;SQ&gt;, &lt;(&gt;, &lt;VBP&gt;, &lt;)&gt;, &lt;(&gt;,...</td>\n",
       "      <td>[&lt;SOS&gt;, D@@, o, G@@, +, \"@@, plus, on@@, es@@,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[C@@, an, ll@@, p, give, loan, to, its, partne...</td>\n",
       "      <td>[&lt;(&gt;, &lt;ROOT&gt;, &lt;(&gt;, &lt;SQ&gt;, &lt;(&gt;, &lt;MD&gt;, &lt;)&gt;, &lt;(&gt;, ...</td>\n",
       "      <td>[&lt;SOS&gt;, C@@, an, ll@@, p, give, loan, to, its,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[H@@, ow, many, medals, become, won, in, O@@, ...</td>\n",
       "      <td>[&lt;(&gt;, &lt;ROOT&gt;, &lt;(&gt;, &lt;SBARQ&gt;, &lt;(&gt;, &lt;WHNP&gt;, &lt;(&gt;, ...</td>\n",
       "      <td>[&lt;SOS&gt;, H@@, ow, many, medals, become, won, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  [W@@, hy, won@@, 't, C@@, h@@, ina, let, P@@, ...   \n",
       "1  [I@@, s, it, common, to, say, \"@@, you, are, w...   \n",
       "2  [D@@, o, G@@, +, \"@@, plus, on@@, es@@, \", on,...   \n",
       "3  [C@@, an, ll@@, p, give, loan, to, its, partne...   \n",
       "4  [H@@, ow, many, medals, become, won, in, O@@, ...   \n",
       "\n",
       "                                              parser  \\\n",
       "0  [<(>, <ROOT>, <(>, <SBARQ>, <(>, <WHADVP>, <(>...   \n",
       "1  [<(>, <ROOT>, <(>, <SQ>, <(>, <VBZ>, <)>, <(>,...   \n",
       "2  [<(>, <ROOT>, <(>, <SQ>, <(>, <VBP>, <)>, <(>,...   \n",
       "3  [<(>, <ROOT>, <(>, <SQ>, <(>, <MD>, <)>, <(>, ...   \n",
       "4  [<(>, <ROOT>, <(>, <SBARQ>, <(>, <WHNP>, <(>, ...   \n",
       "\n",
       "                                              target  \n",
       "0  [<SOS>, W@@, hy, won@@, 't, C@@, h@@, ina, let...  \n",
       "1  [<SOS>, I@@, s, it, common, to, say, \"@@, you,...  \n",
       "2  [<SOS>, D@@, o, G@@, +, \"@@, plus, on@@, es@@,...  \n",
       "3  [<SOS>, C@@, an, ll@@, p, give, loan, to, its,...  \n",
       "4  [<SOS>, H@@, ow, many, medals, become, won, in...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data/dictionary.pkl', 'rb') as f:\n",
    "    vocab_transform = pickle.load(f)\n",
    "vocab_dict = vocab_transform.word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer('spacy',language='en_core_web_sm')\n",
    "text_pipeline = lambda x: [vocab_dict[x_] if x_ in vocab_dict else vocab_dict[\"<unk>\"] for x_ in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "setence_token_id = text_pipeline(train_load['sentence'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21396, 16180, 14060, 16778, 14933,   775,  2824,   216, 22548,  1939,\n",
       "          614, 23229,  3860, 18657, 28121,   119])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.tensor(setence_token_id, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "pad_idx = vocab_dict['<pad>'] ##get the pad index from the vocab\n",
    "\n",
    "def collate_batch(batch):\n",
    "    sent_list, synt_lst, trg_list = [], [], []\n",
    "    for sen_, syn_, trg_ in batch:\n",
    "        processed_sent = torch.tensor(text_pipeline(sen_), dtype=torch.int64)\n",
    "        sent_list.append(processed_sent)\n",
    "        processed_synt = torch.tensor(text_pipeline(syn_), dtype=torch.int64)\n",
    "        synt_lst.append(processed_synt)\n",
    "        processed_trg = torch.tensor(text_pipeline(trg_), dtype=torch.int64)\n",
    "        trg_list.append(processed_trg)\n",
    "\n",
    "    return pad_sequence(sent_list, padding_value=pad_idx, batch_first=True), pad_sequence(synt_lst, padding_value=pad_idx, batch_first=True), pad_sequence(trg_list, padding_value=pad_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class DataWrap(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataframe.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "torch.manual_seed(6969)\n",
    "\n",
    "train = DataWrap(train_load.iloc[:800])\n",
    "val   = DataWrap(train_load.iloc[800:900])\n",
    "test  = DataWrap(train_load.iloc[900:])\n",
    "train_dataloader = DataLoader(train,batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(val,  batch_size=16)\n",
    "test_dataloader = DataLoader(test,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Guntsv\\Documents\\GitHub\\Thai-Paraphase\\quora_tokenize.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# for sen,syn,trg in train_dataloader:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#     print(sen)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#     print(syn)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#     print(trg)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#     break\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m i,j,k \u001b[39m=\u001b[39m  train_load\u001b[39m.\u001b[39miloc[:\u001b[39m10\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m collate_batch([[i],[j],[k]])\n",
      "\u001b[1;32mc:\\Users\\Guntsv\\Documents\\GitHub\\Thai-Paraphase\\quora_tokenize.ipynb Cell 23\u001b[0m in \u001b[0;36mcollate_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollate_batch\u001b[39m(batch):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     sent_list, synt_lst, trg_list \u001b[39m=\u001b[39m [], [], []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m sen_, syn_, trg_ \u001b[39min\u001b[39;00m batch:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         processed_sent \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(text_pipeline(sen_), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         sent_list\u001b[39m.\u001b[39mappend(processed_sent)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "# for sen,syn,trg in train_dataloader:\n",
    "#     print(sen)\n",
    "#     print(syn)\n",
    "#     print(trg)\n",
    "#     break\n",
    "i,j,k =  train_load.iloc[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Guntsv\\Documents\\GitHub\\Thai-Paraphase\\quora_tokenize.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m l,h2,h \u001b[39min\u001b[39;00m [i,j,k]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/Thai-Paraphase/quora_tokenize.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(l,h2,h)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "for l,h2,h in [i,j,k]:\n",
    "    print(l,h2,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
