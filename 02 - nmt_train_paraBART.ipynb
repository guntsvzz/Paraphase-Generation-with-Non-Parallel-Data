{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers.modeling_bart import (\n",
    "    PretrainedBartModel,  \n",
    "    LayerNorm, \n",
    "    EncoderLayer, \n",
    "    DecoderLayer, \n",
    "    LearnedPositionalEmbedding,\n",
    "    _prepare_bart_decoder_inputs,\n",
    "    _make_linear_from_emb\n",
    ")\n",
    "\n",
    "import os, argparse, pickle, h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from utils import Timer, make_path, deleaf\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from transformers import BartTokenizer, BartConfig, BartModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== loading data ====\n"
     ]
    }
   ],
   "source": [
    "import h5py, os\n",
    "print(\"==== loading data ====\")\n",
    "num = 1000000\n",
    "para_data = h5py.File(os.path.join('./data/data.h5'), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['train_sents1', 'train_sents2', 'train_synts1', 'train_synts2']>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers.modeling_bart import (\n",
    "    PretrainedBartModel,  \n",
    "    LayerNorm, \n",
    "    EncoderLayer, \n",
    "    DecoderLayer, \n",
    "    LearnedPositionalEmbedding,\n",
    "    _prepare_bart_decoder_inputs,\n",
    "    _make_linear_from_emb\n",
    ")\n",
    "\n",
    "class ParaBart(PretrainedBartModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.shared = nn.Embedding(config.vocab_size, config.d_model, config.pad_token_id)\n",
    "\n",
    "        self.encoder = ParaBartEncoder(config, self.shared)\n",
    "        self.decoder = ParaBartDecoder(config, self.shared)\n",
    "                \n",
    "        self.linear = nn.Linear(config.d_model, config.vocab_size)\n",
    "        \n",
    "        self.adversary = Discriminator(config)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,      \n",
    "        decoder_input_ids,\n",
    "        attention_mask=None,\n",
    "        decoder_padding_mask=None,\n",
    "        encoder_outputs=None,\n",
    "        return_encoder_outputs=False,\n",
    "    ):\n",
    "        if attention_mask is None:\n",
    "            attention_mask = input_ids == self.config.pad_token_id\n",
    "        \n",
    "        if encoder_outputs is None:\n",
    "            encoder_outputs = self.encoder(input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "        if return_encoder_outputs:\n",
    "            return encoder_outputs\n",
    "        \n",
    "        assert encoder_outputs is not None\n",
    "        assert decoder_input_ids is not None\n",
    "\n",
    "        decoder_input_ids = decoder_input_ids[:, :-1]\n",
    "                \n",
    "        _, decoder_padding_mask, decoder_causal_mask = _prepare_bart_decoder_inputs(\n",
    "            self.config,\n",
    "            input_ids=None,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_padding_mask=decoder_padding_mask,\n",
    "            causal_mask_dtype=self.shared.weight.dtype,\n",
    "        )    \n",
    "\n",
    "        attention_mask2 = torch.cat((torch.zeros(input_ids.shape[0], 1).bool().cuda(), attention_mask[:, self.config.max_sent_len+2:]), dim=1)\n",
    "           \n",
    "        # decoder\n",
    "        decoder_outputs = self.decoder(\n",
    "            decoder_input_ids,\n",
    "            torch.cat((encoder_outputs[1], encoder_outputs[0][:, self.config.max_sent_len+2:]), dim=1),           \n",
    "            decoder_padding_mask=decoder_padding_mask,\n",
    "            decoder_causal_mask=decoder_causal_mask,\n",
    "            encoder_attention_mask=attention_mask2,\n",
    "        )[0]\n",
    "        \n",
    "       \n",
    "        batch_size = decoder_outputs.shape[0]\n",
    "        outputs = self.linear(decoder_outputs.contiguous().view(-1, self.config.d_model))\n",
    "        outputs = outputs.view(batch_size, -1, self.config.vocab_size)\n",
    "        \n",
    "        # discriminator\n",
    "        for p in self.adversary.parameters():\n",
    "            p.required_grad=False\n",
    "        adv_outputs = self.adversary(encoder_outputs[1])        \n",
    "        \n",
    "        return outputs, adv_outputs\n",
    "    \n",
    "    def prepare_inputs_for_generation(self, decoder_input_ids, past, attention_mask, use_cache, **kwargs):\n",
    "        assert past is not None, \"past has to be defined for encoder_outputs\"\n",
    "\n",
    "        encoder_outputs = past[0]\n",
    "        return {\n",
    "            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
    "            \"encoder_outputs\": encoder_outputs,\n",
    "            \"decoder_input_ids\": torch.cat((decoder_input_ids, torch.zeros((decoder_input_ids.shape[0], 1), dtype=torch.long).cuda()), 1),\n",
    "            \"attention_mask\": attention_mask,\n",
    "        }\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return _make_linear_from_emb(self.shared)\n",
    "    \n",
    "    def get_input_embeddings(self):\n",
    "        return self.shared\n",
    "    \n",
    "    @staticmethod\n",
    "    def _reorder_cache(past, beam_idx):\n",
    "        enc_out = past[0][0]\n",
    "\n",
    "        new_enc_out = enc_out.index_select(0, beam_idx)\n",
    "\n",
    "        past = ((new_enc_out, ), )\n",
    "        return past\n",
    "\n",
    "    def forward_adv(\n",
    "        self,\n",
    "        input_token_ids,      \n",
    "        attention_mask=None,\n",
    "        decoder_padding_mask=None\n",
    "    ):\n",
    "        for p in self.adversary.parameters():\n",
    "            p.required_grad=True\n",
    "        sent_embeds = self.encoder.embed(input_token_ids, attention_mask=attention_mask).detach()\n",
    "        adv_outputs = self.adversary(sent_embeds)\n",
    "\n",
    "        return adv_outputs\n",
    "\n",
    "    def generate(self, input_ids, decoder_input_ids, attention_mask=None,decoder_padding_mask=None,\n",
    "                 encoder_outputs=None,return_encoder_outputs=False, \n",
    "                 max_len = 40, sample=True, temp=0.5):\n",
    "        \n",
    "        max_targ_len = decoder_input_ids.size(1) - 2\n",
    "        batch_size   = decoder_input_ids.size(0)\n",
    "        # output index starts with <sos>\n",
    "        idxs = torch.zeros((batch_size, max_targ_len +2), dtype=torch.long).cuda()\n",
    "        idxs[:, 0] = 0\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = input_ids == self.config.pad_token_id\n",
    "        \n",
    "        if encoder_outputs is None:\n",
    "            encoder_outputs = self.encoder(input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "        if return_encoder_outputs:\n",
    "            return encoder_outputs\n",
    "        \n",
    "        assert encoder_outputs is not None\n",
    "        assert decoder_input_ids is not None\n",
    "\n",
    "        # decoder_input_ids = decoder_input_ids[:, :1]\n",
    "                \n",
    "        # _, decoder_padding_mask, decoder_causal_mask = _prepare_bart_decoder_inputs(\n",
    "        #     self.config,\n",
    "        #     input_ids=None,\n",
    "        #     decoder_input_ids=decoder_input_ids,\n",
    "        #     decoder_padding_mask=decoder_padding_mask,\n",
    "        #     causal_mask_dtype=self.shared.weight.dtype,\n",
    "        # )    \n",
    "\n",
    "        attention_mask2 = torch.cat((torch.zeros(input_ids.shape[0], 1).bool().cuda(), attention_mask[:, self.config.max_sent_len+2:]), dim=1)\n",
    "           \n",
    "        # decoder\n",
    "        decoder_outputs = self.decoder(\n",
    "            idxs[:, :1],\n",
    "            torch.cat((encoder_outputs[1], encoder_outputs[0][:, self.config.max_sent_len+2:]), dim=1),           \n",
    "            decoder_padding_mask = decoder_padding_mask,\n",
    "            decoder_causal_mask = None,\n",
    "            encoder_attention_mask = attention_mask2,\n",
    "        )[0].transpose(0,1)\n",
    "        # print('decoder_outputs',decoder_outputs.shape)\n",
    "        \n",
    "        # output index starts with <sos>\n",
    "        idxs = torch.zeros((batch_size, max_targ_len+2), dtype=torch.long).to(self.device)\n",
    "        idxs[:, 0] = 1\n",
    "\n",
    "        # auto-regressively generate output\n",
    "        for i in range(1, max_targ_len+2):\n",
    "            batch_size = decoder_outputs.shape[0]\n",
    "            outputs = self.linear(decoder_outputs[-1].contiguous().view(-1, self.config.d_model))\n",
    "            # outputs = outputs.view(batch_size, -1, self.config.vocab_size)\n",
    "            # print('outputs', outputs.shape)\n",
    "            # get argmax index or sample index\n",
    "            if not sample:\n",
    "                values, idx = torch.max(outputs, 1)\n",
    "            else:\n",
    "                probs = F.softmax(outputs/temp, dim=1)\n",
    "                idx = torch.multinomial(probs, 1).squeeze(1)\n",
    "                # print('idx',idx.shape)\n",
    "            # save to output index\n",
    "            idxs[:, i] = idx   \n",
    "      \n",
    "            attention_mask2 = torch.cat((torch.zeros(input_ids.shape[0], 1).bool().cuda(), attention_mask[:, self.config.max_sent_len+2:]), dim=1)\n",
    "           \n",
    "            # decoder\n",
    "            decoder_outputs = self.decoder(\n",
    "                idxs[:, :i+1],\n",
    "                torch.cat((encoder_outputs[1], encoder_outputs[0][:, self.config.max_sent_len+2:]), dim=1),           \n",
    "                decoder_padding_mask = decoder_padding_mask,\n",
    "                decoder_causal_mask =  None,\n",
    "                encoder_attention_mask = attention_mask2,\n",
    "            )[0].transpose(0,1)\n",
    "            # print('decoder_outputs',decoder_outputs.shape)\n",
    "        \n",
    "        return idxs[:, 1:]\n",
    "\n",
    "class ParaBartEncoder(nn.Module):\n",
    "    def __init__(self, config, embed_tokens):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.dropout = config.dropout\n",
    "        self.embed_tokens = embed_tokens\n",
    "                \n",
    "        self.embed_synt = nn.Embedding(77, config.d_model, config.pad_token_id)       \n",
    "        self.embed_synt.weight.data.normal_(mean=0.0, std=config.init_std)\n",
    "        self.embed_synt.weight.data[config.pad_token_id].zero_()\n",
    "\n",
    "        self.embed_positions = LearnedPositionalEmbedding(\n",
    "            config.max_position_embeddings, config.d_model, config.pad_token_id, config.extra_pos_embeddings\n",
    "        )\n",
    "        \n",
    "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n",
    "        self.synt_layers = nn.ModuleList([EncoderLayer(config) for _ in range(1)])\n",
    "\n",
    "        self.layernorm_embedding = LayerNorm(config.d_model) \n",
    "\n",
    "        self.synt_layernorm_embedding = LayerNorm(config.d_model)\n",
    "        \n",
    "        self.pooling = MeanPooling(config)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask): \n",
    "        \n",
    "        input_token_ids, input_synt_ids = torch.split(input_ids, [self.config.max_sent_len+2, self.config.max_synt_len+2], dim=1)\n",
    "        input_token_mask, input_synt_mask = torch.split(attention_mask, [self.config.max_sent_len+2, self.config.max_synt_len+2], dim=1)\n",
    "        \n",
    "        x = self.forward_token(input_token_ids, input_token_mask)\n",
    "        y = self.forward_synt(input_synt_ids, input_synt_mask)\n",
    "                \n",
    "        encoder_outputs = torch.cat((x,y), dim=1)\n",
    "\n",
    "        sent_embeds = self.pooling(x, input_token_ids)\n",
    "\n",
    "        return encoder_outputs, sent_embeds\n",
    "    \n",
    "    def forward_token(self, input_token_ids, attention_mask):\n",
    "        if self.training:\n",
    "            drop_mask = torch.bernoulli(self.config.word_dropout*torch.ones(input_token_ids.shape)).bool().cuda()\n",
    "            input_token_ids = input_token_ids.masked_fill(drop_mask, 50264)\n",
    "               \n",
    "        input_token_embeds = self.embed_tokens(input_token_ids) + self.embed_positions(input_token_ids)\n",
    "        x = self.layernorm_embedding(input_token_embeds)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = x.transpose(0, 1)\n",
    "        \n",
    "        for encoder_layer in self.layers:\n",
    "            x, _ = encoder_layer(x, encoder_padding_mask=attention_mask)\n",
    "            \n",
    "        x = x.transpose(0, 1)\n",
    "        return x\n",
    "        \n",
    "    def forward_synt(self, input_synt_ids, attention_mask):\n",
    "        input_synt_embeds = self.embed_synt(input_synt_ids) + self.embed_positions(input_synt_ids)        \n",
    "        y = self.synt_layernorm_embedding(input_synt_embeds)        \n",
    "        y = F.dropout(y, p=self.dropout, training=self.training)\n",
    "\n",
    "        # B x T x C -> T x B x C\n",
    "        y = y.transpose(0, 1)\n",
    "            \n",
    "        for encoder_synt_layer in self.synt_layers:\n",
    "            y, _ = encoder_synt_layer(y, encoder_padding_mask=attention_mask)\n",
    "\n",
    "        # T x B x C -> B x T x C\n",
    "        y = y.transpose(0, 1)\n",
    "        return y\n",
    "        \n",
    "\n",
    "    def embed(self, input_token_ids, attention_mask=None, pool='mean'):\n",
    "        if attention_mask is None:\n",
    "            attention_mask = input_token_ids == self.config.pad_token_id\n",
    "            \n",
    "        x = self.forward_token(input_token_ids, attention_mask)\n",
    "        \n",
    "        sent_embeds = self.pooling(x, input_token_ids)\n",
    "        return sent_embeds\n",
    "            \n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "    def forward(self, x, input_token_ids):\n",
    "        mask = input_token_ids != self.config.pad_token_id\n",
    "        mean_mask = mask.float()/mask.float().sum(1, keepdim=True)\n",
    "        x = (x*mean_mask.unsqueeze(2)).sum(1, keepdim=True)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ParaBartDecoder(nn.Module):\n",
    "    def __init__(self, config, embed_tokens):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = config.dropout\n",
    "        \n",
    "        self.embed_tokens = embed_tokens\n",
    "        \n",
    "        self.embed_positions = LearnedPositionalEmbedding(\n",
    "            config.max_position_embeddings, config.d_model, config.pad_token_id, config.extra_pos_embeddings\n",
    "        )\n",
    "        \n",
    "        self.layers = nn.ModuleList([DecoderLayer(config) for _ in range(1)]) \n",
    "        self.layernorm_embedding = LayerNorm(config.d_model)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        decoder_input_ids, \n",
    "        encoder_hidden_states,  \n",
    "        decoder_padding_mask, \n",
    "        decoder_causal_mask,  \n",
    "        encoder_attention_mask\n",
    "    ):        \n",
    "\t\t\n",
    "        x = self.embed_tokens(decoder_input_ids) + self.embed_positions(decoder_input_ids)\n",
    "        x = self.layernorm_embedding(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "        encoder_hidden_states = encoder_hidden_states.transpose(0, 1)\n",
    "\n",
    "        for idx, decoder_layer in enumerate(self.layers):\n",
    "            x, _, _ = decoder_layer(\n",
    "                x, \n",
    "                encoder_hidden_states,\n",
    "                encoder_attn_mask=encoder_attention_mask,\n",
    "                decoder_padding_mask=decoder_padding_mask,\n",
    "                causal_mask=decoder_causal_mask)\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "       \n",
    "        return x,\n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.sent_layernorm_embedding = LayerNorm(config.d_model, elementwise_affine=False)\n",
    "        self.adv = nn.Linear(config.d_model, 74)\n",
    "        \n",
    "    def forward(self, sent_embeds):\n",
    "        x = self.sent_layernorm_embedding(sent_embeds).squeeze(1)\n",
    "        x = self.adv(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== loading model ====\n"
     ]
    }
   ],
   "source": [
    "print(\"==== loading model ====\")\n",
    "config = BartConfig.from_pretrained('facebook/bart-base', cache_dir='./bart-base/')\n",
    "config.word_dropout = 0.2\n",
    "config.max_sent_len = 40\n",
    "config.max_synt_len = 160\n",
    "\n",
    "bart = BartModel.from_pretrained('facebook/bart-base', cache_dir='./bart-base/')\n",
    "model = ParaBart(config)\n",
    "# model.load_state_dict(bart.state_dict(), strict=False)\n",
    "model.zero_grad()\n",
    "del bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParaBart(\n",
       "  (shared): Embedding(50265, 768, padding_idx=1)\n",
       "  (encoder): ParaBartEncoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_synt): Embedding(77, 768, padding_idx=1)\n",
       "    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): SelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): SelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): SelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (self_attn): SelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (self_attn): SelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (self_attn): SelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (synt_layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): SelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (synt_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (pooling): MeanPooling()\n",
       "  )\n",
       "  (decoder): ParaBartDecoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): SelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): SelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  (adversary): Discriminator(\n",
       "    (sent_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=False)\n",
       "    (adv): Linear(in_features=768, out_features=74, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'you were trying to take something back .',\n",
       " b'you just wanted something for it .')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_data['train_sents1'][1], para_data['train_sents2'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train examples: 970000\n",
      "number of valid examples: 30000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "\n",
    "train_idxs, valid_idxs = random_split(range(num), [num-30000, 30000], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "print(f\"number of train examples: {len(train_idxs)}\")\n",
    "print(f\"number of valid examples: {len(valid_idxs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== preparing data ====\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_idxs, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_idxs, batch_size=16, shuffle=False)\n",
    "\n",
    "print(\"==== preparing data ====\")\n",
    "make_path('./bart-base/')\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', cache_dir='./bart-base/')\n",
    "\n",
    "with open('synt_vocab.pkl', 'rb') as f:\n",
    "    synt_vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open('./data/dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump(dataset, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(\"./data/dataset.pkl\", \"rb\") as file:\n",
    "    dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', cache_dir='./bart-base/')\n",
    "config = BartConfig.from_pretrained('facebook/bart-base', cache_dir='./bart-base/')\n",
    "\n",
    "# Get the vocabulary from the tokenizer\n",
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v:k for k,v in vocab.items()}\n",
    "span_vocab = vocab.copy()\n",
    "span_vocab.pop('<s>')\n",
    "span_vocab.pop('<pad>')\n",
    "span_vocab.pop('</s>')\n",
    "span_vocab.pop('<unk>')\n",
    "span_vocab.pop('<mask>')\n",
    "\n",
    "def reverse_bpe(sent):\n",
    "    x = []\n",
    "    cache = ''\n",
    "\n",
    "    for w in sent:\n",
    "        if w.startswith('Ġ'):\n",
    "            cache += w.replace('Ġ', '')\n",
    "            # cache = cache.strip()\n",
    "        elif cache != '':\n",
    "            x.append(cache + w)\n",
    "            cache = ''\n",
    "        else:\n",
    "            x.append(w)\n",
    "\n",
    "    return ' '.join(x)\n",
    "\n",
    "def sent2str(sent, vocab):\n",
    "    return \" \".join([idx2word[i] for i in sent if i != vocab[\"<pad>\"]])\n",
    "\n",
    "def synt2str(synt, vocab):\n",
    "    eos_pos = np.where(synt==vocab[\"</s>\"])[0]\n",
    "    eos_pos = eos_pos[0] if len(eos_pos) > 0 else len(synt)\n",
    "    return \" \".join([idx2word[i][1:-1] if i in span_vocab.values() else idx2word[i] for i in synt[:eos_pos]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v:k for k,v in vocab.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ġenjoyed'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[3776]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==== loading model ====\")\n",
    "config = BartConfig.from_pretrained('facebook/bart-base', cache_dir=\"./bart-base/\")\n",
    "embed_model = ParaBart(config)\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', cache_dir=\"./bart-base/\")\n",
    "model.load_state_dict(torch.load(os.path.join(\"./model/model.pt\"), map_location='cpu'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2str(sent,something=None):\n",
    "    return \" \".join([idx2word[i].replace('Ġ','') for i in sent if i != vocab[\"<pad>\"]]).split('</s>')[0]\n",
    "\n",
    "\n",
    "def generate(model, valid_loader, vocab_transform):\n",
    "    #turn off dropout (and batch norm if used)\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with open(\"./eval_via2/target_sents_parabart.txt\", \"w\") as target_sent, \\\n",
    "         open(\"./eval_via2/target_synts_parabart.txt\", \"w\") as syntax_keep, \\\n",
    "         open(\"./eval_via2/outputs_parabart.txt\", \"w\") as output_sentence,\\\n",
    "         open(\"./eval_via2/inputs_parabart.txt\", \"w\") as input_sentences:\n",
    "        with torch.no_grad():\n",
    "            for idxs in tqdm(valid_loader):\n",
    "                \n",
    "                sent1_token_ids = dataset['sent1'][idxs].cuda()\n",
    "                synt1_token_ids = dataset['synt1'][idxs].cuda()\n",
    "                sent2_token_ids = dataset['sent2'][idxs].cuda()\n",
    "                synt2_token_ids = dataset['synt2'][idxs].cuda()\n",
    "                synt1_bow = dataset['synt1bow'][idxs].cuda()\n",
    "                synt2_bow = dataset['synt2bow'][idxs].cuda()\n",
    "\n",
    "                # generate\n",
    "                idxs = model.generate(torch.cat((sent1_token_ids, synt2_token_ids),1), sent1_token_ids, temp=0.5)\n",
    "                \n",
    "                for sent, idx,sent2, synt,synt2 in zip(sent1_token_ids.cpu().numpy(), idxs.cpu().numpy(),sent2_token_ids.cpu().numpy(), synt1_token_ids.cpu().numpy(), synt2_token_ids.cpu().numpy()):\n",
    "                    \n",
    "                    # print('Text Generated From model')\n",
    "                    # print('Sent1(input) ',sent2str(sent[1:-1], vocab_transform))\n",
    "                    # print('OUTPUT',sent2str(idx, vocab_transform))\n",
    "                    # print('SENT2(ans)',sent2str(sent2[1:-1], vocab_transform))\n",
    "                    # print('return in IDX')\n",
    "                    # print(sent,'\\n')\n",
    "                    # print(idx,'\\n')\n",
    "                    # print(sent2)\n",
    "                    # print('REturn in syntax IDX')\n",
    "                    \n",
    "\n",
    "                    # break\n",
    "            \n",
    "                # print(idxs)\n",
    "                # break\n",
    "                    # convert_sent = reverse_bpe(sent2str(sent[1:], vocab_transform).split()) + '\\n'\n",
    "                    # convert_synt = synt2str(synt[1:], vocab_transform).replace(\"<pad>\", \"\") + '\\n' \n",
    "                    # convert_idx = synt2str(idx, vocab_transform) +'\\n'\n",
    "                    convert_idx_out =sent2str(idx, None)\n",
    "                    targetSent = sent2str(sent2[1:-1],None) \n",
    "                    inputSente = sent2str(sent[1:-1],None) \n",
    "                    input_sentences.write(inputSente+'\\n')\n",
    "                    target_sent.write(targetSent+'\\n') \n",
    "                    output_sentence.write(convert_idx_out+'\\n')\n",
    "                    # fp1.write(convert_sent)\n",
    "\n",
    "                    # fp2.write(convert_synt)\n",
    "                    # fp3.write(convert_idx)\n",
    "                    \n",
    "                    # fp1.write(sent2str(sent, vocab_transform) +'\\n')\n",
    "                    # fp2.write(synt2str(synt[1:], vocab_transform)+'\\n')\n",
    "                    # fp3.write(reverse_bpe(synt2str(idx, vocab_transform).replace(\"<pad>\", \"\")) +'\\n')\n",
    "                    \n",
    "                    # print(synt2str(synt[1:], vocab_transform)+'\\n')\n",
    "                    # print(sent2str(sent, vocab_transform)+'\\n')\n",
    "                    # print(synt2str(idx, vocab_transform)+'\\n')\n",
    "                    # print(\"--\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# generate(model, valid_loader, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:38<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "generate(model, valid_loader, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def cal_bleu(hypothesis, reference, n):\n",
    "    hypothesis = hypothesis.strip().split(' ')\n",
    "    reference = reference.strip().split(' ')\n",
    "\n",
    "    if n == 0:\n",
    "        return sentence_bleu([reference], hypothesis)\n",
    "    elif n == 1:\n",
    "        weights = (1, 0, 0, 0)\n",
    "    elif n == 2:\n",
    "        weights = (0, 1, 0, 0)\n",
    "    elif n == 3:\n",
    "        weights = (0, 0, 1, 0)\n",
    "    elif n == 4:\n",
    "        weights = (0, 0, 0, 1)\n",
    "\n",
    "    return sentence_bleu([reference], hypothesis, weights=weights)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples: 30000 , 30000\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open('./eval_via2/target_sents_parabart.txt') as fp:\n",
    "    targs = fp.readlines()\n",
    "with open('./eval_via2/outputs_parabart.txt') as fp:\n",
    "    preds = fp.readlines()\n",
    "with open('./eval_via2/inputs_parabart.txt') as fp:\n",
    "    inps = fp.readlines()\n",
    "\n",
    "print(f\"number of examples: {len(preds)} , {len(targs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  that should be obvious enough . \n",
      " PREDICT:  it ' s clear enough . \n",
      " REAL TARGET:  it ' s obvious enough . \n",
      "\n",
      "INPUT:  i am a man of principle \n",
      " PREDICT:  i ' m a principled man . \n",
      " REAL TARGET:  i ' m a principled man . \n",
      "\n",
      "INPUT:  i ' ve been working on this puppet all night . \n",
      " PREDICT:  i ' m doing the puppet all night . \n",
      " REAL TARGET:  i ' m doing this puppet all night . \n",
      "\n",
      "INPUT:  after they tortured him he was in awful shape . \n",
      " PREDICT:  after the torture , he was tortured . \n",
      " REAL TARGET:  after the torture , he was terrible . \n",
      "\n",
      "INPUT:  we apprehended the thieves and got your money . \n",
      " PREDICT:  mr . wild er , we have arrested the money for your arrest . \n",
      " REAL TARGET:  mr . dun can , we have arrested a thief with your money . \n",
      "\n",
      "INPUT:  do n 't look at me like i do n 't get you what you want . \n",
      " PREDICT:  do n 't look at me like you do n 't get what i want . \n",
      " REAL TARGET:  do n 't look at me like you do n 't know what i want . \n",
      "\n",
      "INPUT:  if you commit a sin , you have to make at onement for that sin . \n",
      " PREDICT:  and when you commit the sin , then you have to redeem yourself . \n",
      " REAL TARGET:  but when you commit a sin , then you have to redeem yourself . \n",
      "\n",
      "INPUT:  it ' s that vict oria ' s secret model . \n",
      " PREDICT:  the vict oria secret model . \n",
      " REAL TARGET:  the vict oria secret model . \n",
      "\n",
      "INPUT:  aw , take my picture . \n",
      " PREDICT:  take a picture of me . \n",
      " REAL TARGET:  take a picture of me . \n",
      "\n",
      "INPUT:  `` she ' s calling my name . \n",
      " PREDICT:  `` he calls me by name . \n",
      " REAL TARGET:  `` he calls me by name . \n",
      "\n",
      "INPUT:  second ly , a measure must give the beneficiary an advantage . \n",
      " PREDICT:  the advantage must be borne by the latter measure . \n",
      " REAL TARGET:  the measure must be favoured by the other beneficiary . \n",
      "\n",
      "INPUT:  it would be a good day for healing . \n",
      " PREDICT:  it would be a good day for healing healing . \n",
      " REAL TARGET:  it could be an ideal day for aver ting sadness . \n",
      "\n",
      "INPUT:  unless se ren a could jar them into participation . \n",
      " PREDICT:  if se ren a does n 't want them to participate . \n",
      " REAL TARGET:  if se ren a does n 't get them to participate . \n",
      "\n",
      "INPUT:  when i return with our prize , all of us shall be young again . \n",
      " PREDICT:  when i return from our youth , we will win them all . \n",
      " REAL TARGET:  when i return with our prey , we will rejuven ate them all . \n",
      "\n",
      "INPUT:  where necessary , equipment must be so designed that dust can enter or escape from the equipment only at specifically designated points . \n",
      " PREDICT:  where appropriate , the equipment must be installed so that the equipment can penetrate or dust directly into particles specially designed . \n",
      " REAL TARGET:  where appropriate , the equipment must be designed so that the dust can penetrate or leak only in places specially designed . \n",
      "\n",
      "INPUT:  you have the right to have an attorney . \n",
      " PREDICT:  you have the right to counsel . \n",
      " REAL TARGET:  you have a right to counsel . \n",
      "\n",
      "INPUT:  let ' s just get in there , have some fun . \n",
      " PREDICT:  let ' s have some fun . \n",
      " REAL TARGET:  let ' s have some fun . \n",
      "\n",
      "INPUT:  ke ith mars , please hold for ver onica mars . \n",
      " PREDICT:  i ' ll take you to ge orge ke lly . \n",
      " REAL TARGET:  i ' ll give it to ver onica mars . \n",
      "\n",
      "INPUT:  he watched one change , and those who got out poured fresh water over their feet and calves . \n",
      " PREDICT:  he saw as they rose , and those who came out was washing their calves and calves with water . \n",
      " REAL TARGET:  he watched as they exchanged , and those who came out were pouring their feet and calves with water . \n",
      "\n",
      "INPUT:  wait , are you okay ? \n",
      " PREDICT:  are you all right ? \n",
      " REAL TARGET:  are you all right ? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "my_list = []\n",
    "for i in range(20):\n",
    "    my_list.append(random.randint(0, 29999))\n",
    "\n",
    "for i in my_list:\n",
    "    print('INPUT: ',inps[i],'PREDICT: ',preds[i],'REAL TARGET: ',targs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "30000it [00:02, 11486.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 52.62544017667068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores0 = [cal_bleu(pred, targ, 0) for pred, targ in tqdm(zip(preds, targs))]\n",
    "print(f\"BLEU: {np.mean(scores0)*100.0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 52.62544017667068\n"
     ]
    }
   ],
   "source": [
    "print(f\"BLEU0: {np.mean(scores0)*100.0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30000it [00:02, 11636.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 78.18135261314593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores1 = [cal_bleu(pred, targ, 1) for pred, targ in tqdm(zip(preds, targs))]\n",
    "print(f\"BLEU1: {np.mean(scores1)*100.0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30000it [00:02, 11207.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 62.51368605573452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores2 = [cal_bleu(pred, targ, 2) for pred, targ in tqdm(zip(preds, targs))]\n",
    "print(f\"BLEU2: {np.mean(scores2)*100.0}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30000it [00:04, 6348.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METHEO: 76.85368998750661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk.translate import meteor\n",
    "\n",
    "def cal_meteor(hypothesis, reference):\n",
    "    hypothesis = hypothesis.strip().split(' ')\n",
    "    reference = reference.strip().split(' ')\n",
    "\n",
    "    return meteor([reference], hypothesis)   \n",
    "\n",
    "scoresm = [cal_meteor(pred, targ) for pred, targ in tqdm(zip(preds, targs))]\n",
    "print(f\"METHEO: {np.mean(scoresm)*100.0}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30000it [00:05, 5302.46it/s]\n",
      "30000it [00:05, 5436.66it/s]\n",
      "30000it [00:05, 5451.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "scorerR = Rouge()\n",
    "scoresโร้กอา = [scorerR.get_scores(pred,refs= targ)[0]['rouge-1']['r'] for pred, targ in tqdm(zip(preds, targs))]\n",
    "scoresโร้กพี = [scorerR.get_scores(pred,refs= targ)[0]['rouge-1']['p'] for pred, targ in tqdm(zip(preds, targs))]\n",
    "scoresโร้กเอบ = [scorerR.get_scores(pred,refs= targ)[0]['rouge-1']['f'] for pred, targ in tqdm(zip(preds, targs))]\n",
    "\n",
    "# print(f\"Rouge: {np.mean(scoresโร้ก)*100.0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-r: 78.41709526559467\n",
      "Rouge-p: 79.99293499634233\n",
      "Rouge-f: 79.08401827339524\n"
     ]
    }
   ],
   "source": [
    "# # for ind,k in enumerate(scoresโร้ก):\n",
    "print(f\"Rouge-r: {np.mean(scoresโร้กอา)*100.0}\") \n",
    "print(f\"Rouge-p: {np.mean(scoresโร้กพี)*100.0}\") \n",
    "print(f\"Rouge-f: {np.mean(scoresโร้กเอบ)*100.0}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they made me mother .'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def sent2str_take(sent):\n",
    "#     return \" \".join([idx2word[i].replace('Ġ','') for i in sent if i != vocab[\"<pad>\"] and i!=vocab['</s>']])\n",
    "\n",
    "# # removeG =lambda x:[i.replace('Ġ','') for i in x]\n",
    "# sent2str_take([10010,156,162,985,479])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "บู\n",
      "BLEU0: 52.62544017667068\n",
      "BLEU1: 78.18135261314593\n",
      "BLEU2: 62.51368605573452\n",
      "เมเทโอ้\n",
      "METHEO: 76.85368998750661\n",
      "โร้ก\n",
      "Rouge-r: 78.41709526559467\n",
      "Rouge-p: 79.99293499634233\n",
      "Rouge-f: 79.08401827339524\n"
     ]
    }
   ],
   "source": [
    "print('บู')\n",
    "print(f\"BLEU0: {np.mean(scores0)*100.0}\")\n",
    "print(f\"BLEU1: {np.mean(scores1)*100.0}\")\n",
    "print(f\"BLEU2: {np.mean(scores2)*100.0}\")\n",
    "print('เมเทโอ้')\n",
    "print(f\"METHEO: {np.mean(scoresm)*100.0}\")\n",
    "print('โร้ก')\n",
    "print(f\"Rouge-r: {np.mean(scoresโร้กอา)*100.0}\") \n",
    "print(f\"Rouge-p: {np.mean(scoresโร้กพี)*100.0}\") \n",
    "print(f\"Rouge-f: {np.mean(scoresโร้กเอบ)*100.0}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
