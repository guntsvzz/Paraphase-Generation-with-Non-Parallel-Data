{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "23\n",
      "([114, 311, 13824], [1, 106, 60, 106, 41, 106, 48, 107, 107, 106, 80, 106, 77, 107, 106, 41, 106, 36, 107, 107, 107, 107, 2])\n"
     ]
    }
   ],
   "source": [
    "import benepar, spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe('benepar', config={'model': 'benepar_en3'})\n",
    "\n",
    "#### Configuration\n",
    "def is_paren(tok):\n",
    "    return tok == \")\" or tok == \"(\"\n",
    "\n",
    "def getleaf(tree):\n",
    "    nonleaves = ''\n",
    "    for w in str(tree).replace('\\n', '').split():\n",
    "        w = w.replace('(', '( ').replace(')', ' )')\n",
    "        nonleaves += w + ' '\n",
    "    \n",
    "    leaves = []\n",
    "    arr = nonleaves.split()\n",
    "    for n, i in enumerate(arr):\n",
    "        if n + 1 < len(arr):\n",
    "            tok1 = arr[n]\n",
    "            tok2 = arr[n + 1]\n",
    "            if not is_paren(tok1) and not is_paren(tok2):\n",
    "                leaves.append(arr[n])\n",
    "\n",
    "    return leaves\n",
    "\n",
    "def deleaf(tree):\n",
    "    nonleaves = ''\n",
    "    for w in str(tree).replace('\\n', '').split():\n",
    "        w = w.replace('(', '( ').replace(')', ' )')\n",
    "        nonleaves += w + ' '\n",
    "\n",
    "    arr = nonleaves.split()\n",
    "    for n, i in enumerate(arr):\n",
    "        if n + 1 < len(arr):\n",
    "            tok1 = arr[n]\n",
    "            tok2 = arr[n + 1]\n",
    "            if not is_paren(tok1) and not is_paren(tok2):\n",
    "                arr[n + 1] = \"\"\n",
    "\n",
    "    nonleaves = \" \".join(arr)\n",
    "    return nonleaves.split()\n",
    "\n",
    "#### Dictionary + Dependency\n",
    "new_dep = ['ACL', 'ACOMP', 'ADVCL', 'ADVMOD', 'AGENT', 'AMOD', 'APPOS', 'ATTR', 'AUX', 'AUXPASS', 'CASE','CC', 'CCOMP', 'COMPOUND', 'CONJ', 'CSUBJ', 'CSUBJPASS', 'DATIVE','DEP','DET', 'DOBJ', 'EXPL', 'INTJ', 'MARK', 'META','NEG', 'NOUNMOD', 'NPMOD', 'NSUBJ', 'NSUBJPASS', 'NUMMOD', 'OPRD', 'PARATAXIS', 'PCOMP', 'POBJ', 'POSS', 'PRECONJ', 'PREDET', 'PREP', 'PRT', 'PUNCT', 'QUANTMOD', 'RELCL', 'ROOT', 'XCOMP']\n",
    "deprecated = ['COMPLM', 'INFMOD', 'PARTMOD', 'HMOD', 'HYPH', 'IOBJ', 'NUM', 'NUMBER', 'NMOD','NN', 'NPADVMOD', 'POSSESSIVE', 'RCMOD']\n",
    "dependency_tags = new_dep + deprecated\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"./data/dictionary.pkl\", \"rb\") as file:\n",
    "    dictionary = pickle.load(file)\n",
    "for i in range(31414, 31414+len(dependency_tags)):\n",
    "    # print(i,dependency_tags[i-31414])\n",
    "    dictionary.idx2word[i] = dependency_tags[i-31414].upper()\n",
    "    a = dependency_tags[i-31414].upper()\n",
    "    dictionary.word2idx[a] = i \n",
    "\n",
    "#### SyntSent\n",
    "from nltk import ParentedTree\n",
    "def syntsent(sentence):\n",
    "    doc   = nlp(sentence.lower())\n",
    "    ###Sentence Token\n",
    "    sent  = list(doc.sents)[0]\n",
    "    sent_ = [dictionary.word2idx[f'{w}'] for w in sent]\n",
    "    ###Syntax Token\n",
    "    synt  = ParentedTree.fromstring(sent._.parse_string)\n",
    "    synt  = deleaf(synt)\n",
    "    synt  = [dictionary.word2idx[f\"<{w}>\"] for w in synt if f\"<{w}>\" in dictionary.word2idx]\n",
    "    synt_ = [dictionary.word2idx[\"<sos>\"]] + synt + [dictionary.word2idx[\"<eos>\"]]\n",
    "    return sent_, synt_\n",
    "\n",
    "ss = syntsent('I love sushi')\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
