{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, h5py\n",
    "para_data = h5py.File('data.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"data.h5\" (mode r)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import deleaf\n",
    "num = 100000\n",
    "synts1 = list(para_data['train_synts1'][:num])\n",
    "\n",
    "synt1 = ['<s>'] + deleaf(synts1[2]) + ['</s>'] for i in range(1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('synt_vocab.pkl', 'rb') as f:\n",
    "    synt_vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from utils import deleaf\n",
    "\n",
    "def prepare_dataset(para_data, tokenizer, num):\n",
    "    sents1 = list(para_data['train_sents1'][:num])\n",
    "    synts1 = list(para_data['train_synts1'][:num])\n",
    "    sents2 = list(para_data['train_sents2'][:num])\n",
    "    synts2 = list(para_data['train_synts2'][:num])\n",
    "\n",
    "    sent1_token_ids = torch.ones((num, args.max_sent_len+2), dtype=torch.long) \n",
    "    sent2_token_ids = torch.ones((num, args.max_sent_len+2), dtype=torch.long)    \t\t\n",
    "    synt1_token_ids = torch.ones((num, args.max_synt_len+2), dtype=torch.long) \n",
    "    synt2_token_ids = torch.ones((num, args.max_synt_len+2), dtype=torch.long)\n",
    "    synt1_bow = torch.ones((num, 74))\n",
    "    synt2_bow = torch.ones((num, 74))\n",
    "        \n",
    "    bsz = 64\n",
    "    \n",
    "    for i in tqdm(range(0, num, bsz)):\n",
    "        sent1_inputs = tokenizer(sents1[i:i+bsz], padding='max_length', truncation=True, max_length=args.max_sent_len+2, return_tensors=\"pt\")\n",
    "        sent2_inputs = tokenizer(sents2[i:i+bsz], padding='max_length', truncation=True, max_length=args.max_sent_len+2, return_tensors=\"pt\")\n",
    "        sent1_token_ids[i:i+bsz] = sent1_inputs['input_ids']\n",
    "        sent2_token_ids[i:i+bsz] = sent2_inputs['input_ids']\n",
    "\n",
    "    for i in tqdm(range(num)):\n",
    "        synt1 = ['<s>'] + deleaf(synts1[i]) + ['</s>']\n",
    "        synt1_token_ids[i, :len(synt1)] = torch.tensor([synt_vocab[tag] for tag in synt1])[:args.max_synt_len+2]\n",
    "        synt2 = ['<s>'] + deleaf(synts2[i]) + ['</s>']\n",
    "        synt2_token_ids[i, :len(synt2)] = torch.tensor([synt_vocab[tag] for tag in synt2])[:args.max_synt_len+2]\n",
    "        \n",
    "        for tag in synt1:\n",
    "            if tag != '<s>' and tag != '</s>':\n",
    "                synt1_bow[i][synt_vocab[tag]-3] += 1\n",
    "        for tag in synt2:\n",
    "            if tag != '<s>' and tag != '</s>':\n",
    "                synt2_bow[i][synt_vocab[tag]-3] += 1\n",
    "\n",
    "    synt1_bow /= synt1_bow.sum(1, keepdim=True)\n",
    "    synt2_bow /= synt2_bow.sum(1, keepdim=True)\n",
    "    \n",
    "    sum = 0\n",
    "    for i in range(num):\n",
    "        if torch.equal(synt1_bow[i], synt2_bow[i]):\n",
    "            sum += 1\n",
    "\n",
    "    return {'sent1':sent1_token_ids, 'sent2':sent2_token_ids, 'synt1': synt1_token_ids, 'synt2': synt2_token_ids,\n",
    "            'synt1bow': synt1_bow, 'synt2bow': synt2_bow}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(para_data, tokenizer, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "check = torch.ones((1000000, 74))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleaf(tree):\n",
    "    nonleaves = ''\n",
    "    for w in str(tree).replace('\\n', '').split():\n",
    "        w = w.replace('(', '( ').replace(')', ' )')\n",
    "        nonleaves += w + ' '\n",
    "\n",
    "    arr = nonleaves.split()\n",
    "    for n, i in enumerate(arr):\n",
    "        if n + 1 < len(arr):\n",
    "            tok1 = arr[n]\n",
    "            tok2 = arr[n + 1]\n",
    "            if not is_paren(tok1) and not is_paren(tok2):\n",
    "                arr[n + 1] = \"\"\n",
    "\n",
    "    nonleaves = \" \".join(arr)\n",
    "    return nonleaves.split()\n",
    "\n",
    "def is_paren(tok):\n",
    "    return tok == \")\" or tok == \"(\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (SQ\n",
      "    (MD can)\n",
      "    (NP (PRP you))\n",
      "    (VP (VB adjust) (NP (DT the) (NNS cameras)))\n",
      "    (. ?)))\n",
      "['(', 'ROOT', '(', 'SQ', '(', 'MD', ')', '(', 'NP', '(', 'PRP', ')', ')', '(', 'VP', '(', 'VB', ')', '(', 'NP', '(', 'DT', ')', '(', 'NNS', ')', ')', ')', '(', '.', ')', ')', ')']\n"
     ]
    }
   ],
   "source": [
    "from nltk import ParentedTree\n",
    "\n",
    "# parse syntax and convert to tensor\n",
    "synt_ = '(ROOT (SQ (MD can) (NP (PRP you)) (VP (VB adjust) (NP (DT the) (NNS cameras))) (. ?)))'\n",
    "synt_ = ParentedTree.fromstring(synt_)\n",
    "print(synt_)\n",
    "synt_ = deleaf(synt_)\n",
    "print(synt_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (SQ\n",
      "    (MD can)\n",
      "    (NP (PRP you))\n",
      "    (VP (VB adjust) (NP (DT the) (NNS cameras)))\n",
      "    (. ?)))\n",
      "(ROOT (SQ (MD) (NP) (VP) (.)))\n"
     ]
    }
   ],
   "source": [
    "#parse syntax and get template\n",
    "from nltk import ParentedTree\n",
    "\n",
    "def tree2tmpl(tree, level, mlevel):\n",
    "    if level == mlevel:\n",
    "        for idx, n in enumerate(tree):\n",
    "            if isinstance(n, ParentedTree):\n",
    "                tree[idx] = \"(\" + n.label() + \")\"\n",
    "    else:\n",
    "        for n in tree:\n",
    "            tree2tmpl(n, level + 1, mlevel)\n",
    "\n",
    "\n",
    "tmpl_ = '(ROOT (SQ (MD can) (NP (PRP you)) (VP (VB adjust) (NP (DT the) (NNS cameras))) (. ?)))'\n",
    "tmpl_ = ParentedTree.fromstring(tmpl_)\n",
    "print(tmpl_)\n",
    "tree2tmpl(tmpl_, 1, 2)\n",
    "print(tmpl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_paren(tok):\n",
    "    return tok == \")\" or tok == \"(\"\n",
    "\n",
    "def getleaf(tree):\n",
    "    nonleaves = ''\n",
    "    for w in str(tree).replace('\\n', '').split():\n",
    "        w = w.replace('(', '( ').replace(')', ' )')\n",
    "        nonleaves += w + ' '\n",
    "    \n",
    "    leaves = []\n",
    "    arr = nonleaves.split()\n",
    "    for n, i in enumerate(arr):\n",
    "        if n + 1 < len(arr):\n",
    "            tok1 = arr[n]\n",
    "            tok2 = arr[n + 1]\n",
    "            if not is_paren(tok1) and not is_paren(tok2):\n",
    "                leaves.append(arr[n])\n",
    "\n",
    "    return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (SQ\n",
      "    (MD can)\n",
      "    (NP (PRP you))\n",
      "    (VP (VB adjust) (NP (DT the) (NNS cameras)))\n",
      "    (. ?)))\n",
      "['MD', 'PRP', 'VB', 'DT', 'NNS', '.']\n"
     ]
    }
   ],
   "source": [
    "#tag Sequence\n",
    "sent_  = '(ROOT (SQ (MD can) (NP (PRP you)) (VP (VB adjust) (NP (DT the) (NNS cameras))) (. ?)))'\n",
    "sent_ = ParentedTree.fromstring(sent_)\n",
    "print(sent_)\n",
    "sent_ = getleaf(sent_)\n",
    "print(sent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MD', 'PRP', 'VB', 'DT', 'NNS', '.']\n",
      "(ROOT (SQ (MD) (NP) (VP) (.)))\n",
      "['(', 'ROOT', '(', 'SQ', '(', 'MD', ')', '(', 'NP', '(', 'PRP', ')', ')', '(', 'VP', '(', 'VB', ')', '(', 'NP', '(', 'DT', ')', '(', 'NNS', ')', ')', ')', '(', '.', ')', ')', ')']\n"
     ]
    }
   ],
   "source": [
    "print(sent_) #tag1 is the tag sequence of x1\n",
    "print(tmpl_) #t2 is the template of p2\n",
    "print(synt_) #target X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
